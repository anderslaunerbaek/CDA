{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transferlearning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from my_class import my_class as my\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def performance(pred, Y):\n",
    "    \"\"\"\n",
    "    asd\n",
    "    \"\"\"\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    import numpy as np\n",
    "\n",
    "    def array_to_latex(tbl):\n",
    "        for ii in range(tbl.shape[0]):\n",
    "            tmp_str = ''\n",
    "            for jj in range(tbl.shape[1]):\n",
    "                if jj != 0:\n",
    "                    tmp_str += ' & ' + \"{:.0f}\".format(tbl[ii,jj])  \n",
    "                else:\n",
    "                    tmp_str += \"{:.0f}\".format(tbl[ii,jj]) \n",
    "\n",
    "            tmp_str += ' \\\\\\\\ '\n",
    "            print(tmp_str)\n",
    "\n",
    "    def performance_measure(pred_test, Y_test):\n",
    "        #\n",
    "        cm = confusion_matrix(y_pred = pred_test,\n",
    "            y_true = Y_test, \n",
    "            labels = list(range(len(set(Y_test)))))\n",
    "        TP = np.diag(cm)\n",
    "        FP = np.sum(cm, axis=0) - np.diag(cm)\n",
    "        FN = np.sum(cm,axis=1) - np.diag(cm)\n",
    "        TN = np.sum(cm) - (FP+FN+TP)\n",
    "        #\n",
    "        precision = TP/ (TP + FP)\n",
    "        recall = TP / (TP + FN)\n",
    "        F1 = np.multiply(2, np.multiply(precision, recall) / np.add(precision, recall))\n",
    "        acc = (TP+TN)/(TP+FP+FN+TN)\n",
    "        #\n",
    "        return TP, FP, precision, recall, F1, acc, cm\n",
    "\n",
    "\n",
    "    TP, FP, precision, recall, F1, Acc, cm = performance_measure(pred_test=pred, Y_test=np.argmax(Y, axis=1))\n",
    "    print('--------------------------------------------')\n",
    "    print('Average for all classes')\n",
    "    print('Accurcy:   %f' %(np.mean(Acc)))\n",
    "    print('Precision: %f' %(np.mean(precision)))\n",
    "    print('Recall:    %f' %(np.mean(recall)))\n",
    "    print('F1:        %f' %(np.mean(F1)))\n",
    "\n",
    "    #\n",
    "    print(\"std.\\n\")\n",
    "    array_to_latex(cm)\n",
    "    # \n",
    "    print(\"\\npct.\\n\")\n",
    "    cm_norm = cm / cm.astype(np.float).sum(axis=1, keepdims=True) * 100\n",
    "    array_to_latex(cm_norm)\n",
    "\n",
    "    print(\"\\n\\nPaste into latex..\\n\\n\")\n",
    "    tmp = np.ndarray((2,6))\n",
    "    tmp[0:2,0:2] = cm_norm\n",
    "    \n",
    "    tmp[0:2,2] = precision * 100\n",
    "    tmp[0:2,3] = recall * 100\n",
    "    tmp[0:2,4] = F1 * 100\n",
    "    tmp[0:2,5] = Acc * 100\n",
    "    #\n",
    "    array_to_latex(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------\n",
      "Average for all classes\n",
      "Accurcy:   0.891986\n",
      "Precision: 0.892463\n",
      "Recall:    0.891986\n",
      "F1:        0.891953\n",
      "std.\n",
      "\n",
      "251 & 36 \\\\ \n",
      "26 & 261 \\\\ \n",
      "\n",
      "pct.\n",
      "\n",
      "87 & 13 \\\\ \n",
      "9 & 91 \\\\ \n",
      "\n",
      "\n",
      "Paste into latex..\n",
      "\n",
      "\n",
      "87 & 13 & 91 & 87 & 89 & 89 \\\\ \n",
      "9 & 91 & 88 & 91 & 89 & 89 \\\\ \n"
     ]
    }
   ],
   "source": [
    "\n",
    "pred_txt = open(\"./../data/tmp/predictions_marcus.txt\").read().split()\n",
    "label_txt = open(\"./../data/tmp/labels_marcus.txt\").read().split()\n",
    "tjek = np.ndarray((len(label_txt),2))\n",
    "\n",
    "for ii in range(len(pred_txt)):\n",
    "    tjek[ii, 0] = int(float(label_txt[ii]))\n",
    "    tjek[ii, 1] = int(float(pred_txt[ii]))\n",
    "\n",
    "\n",
    "Y = tjek[:, 0].astype(int)\n",
    "b = np.zeros((len(Y), 2))\n",
    "\n",
    "b[np.arange(len(Y)), Y] = 1\n",
    "Y = b\n",
    "\n",
    "# load model\n",
    "performance(tjek[:, 1], Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
