{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transferlearning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from my_class import my_class as my\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set directories\n",
    "data_path_clear = \"./../data/data/clear/billund/2016/\"\n",
    "data_path_foggy = \"./../data/data/foggy/billund/2017/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pic_path_clear = my.list_pics(data_path_clear)\n",
    "pic_path_foggy = my.list_pics(data_path_foggy)\n",
    "pic_path_clear = [pic_path_clear[ii] for ii in range(len(pic_path_clear)) if \".jpg\" in pic_path_clear[ii]]\n",
    "pic_path_foggy = [pic_path_foggy[ii] for ii in range(len(pic_path_foggy)) if \".jpg\" in pic_path_foggy[ii]]\n",
    "\n",
    "\n",
    "#n_sample = 10\n",
    "#pic_path_clear = np.random.choice(pic_path_clear, size=n_sample, replace=False)\n",
    "#pic_path_foggy = np.random.choice(pic_path_foggy, size=n_sample, replace=False)\n",
    "\n",
    "pic_path = np.concatenate((pic_path_clear, pic_path_foggy))\n",
    "# pic_path = [pic_path[ii] for ii in range(len(pic_path)) if \".jpg\" in pic_path[ii]]\n",
    "\n",
    "n_clear = len(pic_path_clear)\n",
    "n_foggy = len(pic_path_foggy)\n",
    "n = len(pic_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Create target variable and feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_clear = np.zeros(n_clear, dtype=int)\n",
    "Y_foggy = np.ones(n_foggy, dtype=int)\n",
    "Y = np.concatenate((Y_clear, Y_foggy), axis=0)\n",
    "# balance(Y)\n",
    "# one hot\n",
    "b = np.zeros((len(Y), len(set(Y))))\n",
    "b[np.arange(len(Y)), Y] = 1\n",
    "Y = b\n",
    "n_classes = Y.shape[1]\n",
    "classes = [\"clear\", \"foggy\"]\n",
    "np.save(\"./../data/tmp/Y_transfer.npy\", Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ratio = 1\n",
    "channels = 3\n",
    "update = True\n",
    "#\n",
    "# if update:\n",
    "if False:\n",
    "    pics = my.img_to_nparr(pic_path=pic_path, \n",
    "                           img_height = 288, \n",
    "                           img_width = 384, \n",
    "                           rat = ratio,\n",
    "                           ch = channels,\n",
    "                           verbose = False)\n",
    "\n",
    "    # only consider the 3 /5 top of the picture...    \n",
    "    #pics = pics[:, 0:int(pics.shape[1] / 5 * 4),:,:]\n",
    "    # dimensions picture\n",
    "    image_height, image_width, _ = pics[1].shape\n",
    "    n_pixels = image_height * image_width"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = [\"Dark channel\", \"sobel_VARsob\", \"sobel_TEN\", \n",
    "            \"laplace_sum\", \"laplace_var\", \"pct_overexposed\"]\n",
    "n_features = len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# if update:\n",
    "if False:\n",
    "    X = np.zeros((n, n_features))\n",
    "    for ii in range(n):\n",
    "        print(str(ii + 1) + \" of \" + str(n), end=\"\\r\")\n",
    "        feature_list = []\n",
    "        # dark channel\n",
    "        dc = my.get_dark_channel(pics[ii], win=20)\n",
    "        # close to 1 -> presents of fog\n",
    "        feature_list.append(np.mean(dc / 255.0)) \n",
    "\n",
    "        # sobel edge filtering\n",
    "        S = my.sobel_filter(pics[ii]),\n",
    "        feature_list.append(my.VARsob(S))\n",
    "        feature_list.append(my.TEN(S) / n_pixels)\n",
    "        \n",
    "        # laplace\n",
    "        L = my.lapalce_filter(pics[ii])\n",
    "        feature_list.append(np.sum(abs(L)) / n_pixels)\n",
    "        feature_list.append(np.var(abs(L)) / n_pixels)\n",
    "        \n",
    "        # pct. overexposed pixels\n",
    "        feature_list.append(my.overexposed_pixels(pics[ii]) / n_pixels)\n",
    "        \n",
    "        # add to design matrix\n",
    "        X[ii,:] = feature_list\n",
    "    # if updated save new... \n",
    "    print(\"Updated...\")\n",
    "    np.save(\"./../data/tmp/X_transfer.npy\", X)\n",
    "else:\n",
    "    X = np.load(\"./../data/tmp/X_transfer.npy\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def performance(pred, Y):\n",
    "    \"\"\"\n",
    "    asd\n",
    "    \"\"\"\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    import numpy as np\n",
    "\n",
    "    def array_to_latex(tbl):\n",
    "        for ii in range(tbl.shape[0]):\n",
    "            tmp_str = ''\n",
    "            for jj in range(tbl.shape[1]):\n",
    "                if jj != 0:\n",
    "                    tmp_str += ' & ' + \"{:.0f}\".format(tbl[ii,jj])  \n",
    "                else:\n",
    "                    tmp_str += \"{:.0f}\".format(tbl[ii,jj]) \n",
    "\n",
    "            tmp_str += ' \\\\\\\\ '\n",
    "            print(tmp_str)\n",
    "\n",
    "    def performance_measure(pred_test, Y_test):\n",
    "        #\n",
    "        cm = confusion_matrix(y_pred = pred_test,\n",
    "            y_true = Y_test, \n",
    "            labels = list(range(len(set(Y_test)))))\n",
    "        TP = np.diag(cm)\n",
    "        FP = np.sum(cm, axis=0) - np.diag(cm)\n",
    "        FN = np.sum(cm,axis=1) - np.diag(cm)\n",
    "        TN = np.sum(cm) - (FP+FN+TP)\n",
    "        #\n",
    "        precision = TP/ (TP + FP)\n",
    "        recall = TP / (TP + FN)\n",
    "        F1 = np.multiply(2, np.multiply(precision, recall) / np.add(precision, recall))\n",
    "        acc = (TP+TN)/(TP+FP+FN+TN)\n",
    "        #\n",
    "        return TP, FP, precision, recall, F1, acc, cm\n",
    "\n",
    "\n",
    "    TP, FP, precision, recall, F1, Acc, cm = performance_measure(pred_test=pred, Y_test=np.argmax(Y, axis=1))\n",
    "    print('--------------------------------------------')\n",
    "    print('Average for all classes')\n",
    "    print('Accurcy:   %f' %(np.mean(Acc)))\n",
    "    print('Precision: %f' %(np.mean(precision)))\n",
    "    print('Recall:    %f' %(np.mean(recall)))\n",
    "    print('F1:        %f' %(np.mean(F1)))\n",
    "\n",
    "    #\n",
    "    print(\"std.\\n\")\n",
    "    array_to_latex(cm)\n",
    "    # \n",
    "    print(\"\\npct.\\n\")\n",
    "    cm_norm = cm / cm.astype(np.float).sum(axis=1, keepdims=True) * 100\n",
    "    array_to_latex(cm_norm)\n",
    "\n",
    "    print(\"\\n\\nPaste into latex..\\n\\n\")\n",
    "    tmp = np.ndarray((2,6))\n",
    "    tmp[0:2,0:2] = cm_norm\n",
    "    \n",
    "    tmp[0:2,2] = precision * 100\n",
    "    tmp[0:2,3] = recall * 100\n",
    "    tmp[0:2,4] = F1 * 100\n",
    "    tmp[0:2,5] = Acc * 100\n",
    "    #\n",
    "    array_to_latex(tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model assessment\n",
    "### Balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.9197815,  0.0802185])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import collections as col\n",
    "tmp = list(dict(col.Counter(np.argmax(Y,1))).values())\n",
    "\n",
    "tmp / np.sum(tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------\n",
      "Average for all classes\n",
      "Accurcy:   0.905726\n",
      "Precision: 0.641259\n",
      "Recall:    0.585244\n",
      "F1:        0.603461\n",
      "std.\n",
      "\n",
      "14491 & 495 \\\\ \n",
      "1041 & 266 \\\\ \n",
      "\n",
      "pct.\n",
      "\n",
      "97 & 3 \\\\ \n",
      "80 & 20 \\\\ \n",
      "\n",
      "\n",
      "Paste into latex..\n",
      "\n",
      "\n",
      "97 & 3 & 93 & 97 & 95 & 91 \\\\ \n",
      "80 & 20 & 35 & 20 & 26 & 91 \\\\ \n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "from sklearn.externals import joblib\n",
    "clf = joblib.load(\"./../data/tmp/clf.pkl\")\n",
    "# make predictions\n",
    "pred = clf.predict(X)\n",
    "performance(pred, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------\n",
      "Average for all classes\n",
      "Accurcy:   0.102375\n",
      "Precision: 0.539614\n",
      "Recall:    0.511695\n",
      "F1:        0.099352\n",
      "std.\n",
      "\n",
      "362 & 14624 \\\\ \n",
      "1 & 1306 \\\\ \n",
      "\n",
      "pct.\n",
      "\n",
      "2 & 98 \\\\ \n",
      "0 & 100 \\\\ \n",
      "\n",
      "\n",
      "Paste into latex..\n",
      "\n",
      "\n",
      "2 & 98 & 100 & 2 & 5 & 10 \\\\ \n",
      "0 & 100 & 8 & 100 & 15 & 10 \\\\ \n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "neigh = joblib.load(\"./../data/tmp/neigh.pkl\")\n",
    "# make predictions\n",
    "pred = neigh.predict(X)\n",
    "performance(pred, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
