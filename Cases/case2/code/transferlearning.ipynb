{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transferlearning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from my_class import my_class as my\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set directories\n",
    "data_path_clear = \"./../data/data/clear/billund/2016/\"\n",
    "data_path_foggy = \"./../data/data/foggy/billund/2017/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pic_path_clear = my.list_pics(data_path_clear)\n",
    "pic_path_foggy = my.list_pics(data_path_foggy)\n",
    "pic_path_clear = [pic_path_clear[ii] for ii in range(len(pic_path_clear)) if \".jpg\" in pic_path_clear[ii]]\n",
    "pic_path_foggy = [pic_path_foggy[ii] for ii in range(len(pic_path_foggy)) if \".jpg\" in pic_path_foggy[ii]]\n",
    "\n",
    "\n",
    "#n_sample = 10\n",
    "#pic_path_clear = np.random.choice(pic_path_clear, size=n_sample, replace=False)\n",
    "#pic_path_foggy = np.random.choice(pic_path_foggy, size=n_sample, replace=False)\n",
    "\n",
    "pic_path = np.concatenate((pic_path_clear, pic_path_foggy))\n",
    "# pic_path = [pic_path[ii] for ii in range(len(pic_path)) if \".jpg\" in pic_path[ii]]\n",
    "\n",
    "n_clear = len(pic_path_clear)\n",
    "n_foggy = len(pic_path_foggy)\n",
    "n = len(pic_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"./../data/tmp/pic_path.npy\", pic_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Create target variable and feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_clear = np.zeros(n_clear, dtype=int)\n",
    "Y_foggy = np.ones(n_foggy, dtype=int)\n",
    "Y = np.concatenate((Y_clear, Y_foggy), axis=0)\n",
    "# balance(Y)\n",
    "# one hot\n",
    "b = np.zeros((len(Y), len(set(Y))))\n",
    "b[np.arange(len(Y)), Y] = 1\n",
    "Y = b\n",
    "n_classes = Y.shape[1]\n",
    "classes = [\"clear\", \"foggy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ratio = 1\n",
    "channels = 3\n",
    "update = True\n",
    "#\n",
    "if update:\n",
    "    pics = my.img_to_nparr(pic_path=pic_path, \n",
    "                           img_height = 288, \n",
    "                           img_width = 384, \n",
    "                           rat = ratio,\n",
    "                           ch = channels,\n",
    "                           verbose = False)\n",
    "\n",
    "    # only consider the 3 /5 top of the picture...    \n",
    "    #pics = pics[:, 0:int(pics.shape[1] / 5 * 4),:,:]\n",
    "    # dimensions picture\n",
    "    image_height, image_width, _ = pics[1].shape\n",
    "    \n",
    "n_pixels = image_height * image_width"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = [\"Dark channel\", \"sobel_VARsob\", \"sobel_TEN\", \n",
    "            \"laplace_sum\", \"laplace_var\", \"pct_overexposed\"]\n",
    "n_features = len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if update:\n",
    "    X = np.zeros((n, n_features))\n",
    "    for ii in range(n):\n",
    "        print(str(ii + 1) + \" of \" + str(n), end=\"\\r\")\n",
    "        feature_list = []\n",
    "        # dark channel\n",
    "        dc = my.get_dark_channel(pics[ii], win=20)\n",
    "        # close to 1 -> presents of fog\n",
    "        feature_list.append(np.mean(dc / 255.0)) \n",
    "\n",
    "        # sobel edge filtering\n",
    "        S = my.sobel_filter(pics[ii]),\n",
    "        feature_list.append(my.VARsob(S))\n",
    "        feature_list.append(my.TEN(S) / n_pixels)\n",
    "        \n",
    "        # laplace\n",
    "        L = my.lapalce_filter(pics[ii])\n",
    "        feature_list.append(np.sum(abs(L)) / n_pixels)\n",
    "        feature_list.append(np.var(abs(L)) / n_pixels)\n",
    "        \n",
    "        # pct. overexposed pixels\n",
    "        feature_list.append(my.overexposed_pixels(pics[ii]) / n_pixels)\n",
    "        \n",
    "        # add to design matrix\n",
    "        X[ii,:] = feature_list\n",
    "    # if updated save new... \n",
    "    print(\"Updated...\")\n",
    "    np.save(\"./../data/tmp/X_transfer.npy\", X)\n",
    "else:\n",
    "    X = np.load(\"./../data/tmp/X_transfer.npy\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model assessment\n",
    "### RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load model\n",
    "from sklearn.externals import joblib\n",
    "clf = joblib.load(\"./../data/tmp/clf.pkl\")\n",
    "# make predictions\n",
    "pred = clf.predict(X)\n",
    "my.performance(pred, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load model\n",
    "neigh = joblib.load(\"./../data/tmp/neigh.pkl\")\n",
    "# make predictions\n",
    "pred = neigh.predict(X)\n",
    "my.performance(pred, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create TF graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reset\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Parameters\n",
    "learning_rate = 0.01\n",
    "training_epochs = 50000\n",
    "batch_size = 100\n",
    "display_step = 1000\n",
    "display_step_state = False\n",
    "\n",
    "# tf Graph Input\n",
    "x = tf.placeholder(tf.float32, [None, n_features])\n",
    "y = tf.placeholder(tf.float32, [None, n_classes])\n",
    "\n",
    "# Set model weights\n",
    "W = tf.Variable(tf.zeros([n_features, n_classes]))\n",
    "b = tf.Variable(tf.zeros([n_classes]))\n",
    "\n",
    "# Construct model\n",
    "pred = tf.nn.softmax(tf.matmul(x, W) + b) # Softmax\n",
    "\n",
    "# Minimize error using cross entropy\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(y*tf.log(pred), reduction_indices=1))\n",
    "\n",
    "# Gradient Descent\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "# optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "# Test model\n",
    "prediction = tf.argmax(pred, 1)\n",
    "correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "# Calculate accuracy\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "# Initialize the variables (i.e. assign their default value)\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Add ops to save and restore all the variables.\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get the test accuracy\n",
    "with tf.Session() as sess:\n",
    "    # restore variables\n",
    "    saver.restore(sess, \"./../data/models/model_final.ckpt\")\n",
    "    print(\"Model restored.\")\n",
    "    # batch norm\n",
    "    X_model = np.load(\"./../data/tmp/X_model.npy\")\n",
    "    _, X_bn = my.batch_normalization(X_model, X, epsilon=.0001)\n",
    "    \n",
    "    # Check the values of the variables\n",
    "    acc_test, pred_test = sess.run([accuracy, prediction], feed_dict={x: X_bn, y: Y})\n",
    "    my.performance(pred_test, Y)\n",
    "    \n",
    "    Weights, bias = sess.run([W, b])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
